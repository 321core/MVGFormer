DEBUG:
  PRINT_TO_FILE: false

CUDNN:
  BENCHMARK: true
  DETERMINISTIC: false
  ENABLED: true
TRANSFORMER: 'dq_transformer'
BACKBONE_MODEL: 'pose_resnet'
MODEL: 'multi_person_posenet'
DATA_DIR: ''
GPUS: '0,1,2,3'
OUTPUT_DIR: 'output'
LOG_DIR: 'log'
WORKERS: 4
PRINT_FREQ: 100

DATASET:
  COLOR_RGB: True
  TRAIN_DATASET: 'campus'
  TEST_DATASET: 'campus'
  DATA_FORMAT: jpg
  DATA_AUGMENTATION: False
  FLIP: False
  ROOT: 'data/CampusSeq1'
  ROT_FACTOR: 45
  SCALE_FACTOR: 0.35
  TEST_SUBSET: 'validation'
  TRAIN_SUBSET: 'train'
  ROOTIDX:
    - 2
    - 3
  CAMERA_NUM: 3
  # PESUDO_GT: 'voxelpose_pesudo_gt_campus.pickle'
  PESUDO_GT: 'voxelpose_pesudo_gt_campus_fix_gtmorethanpred_case.pickle'  # finetune in pesudo generated by voxelpose
  NMS_DETAIL: True
  # NMS_DETAIL_ALL: True  # search the best NMS config
NETWORK:
  PRETRAINED_BACKBONE: "models/pose_resnet50_panoptic.pth.tar" 
  PRETRAINED:  ''
  TARGET_TYPE: gaussian
  IMAGE_SIZE:
    - 1000
    - 800
  HEATMAP_SIZE:
    - 250
    - 200
  SIGMA: 3
  NUM_JOINTS: 15
  USE_GT: False
LOSS:
  USE_TARGET_WEIGHT: true
TRAIN:
  BATCH_SIZE: 1
  SHUFFLE: true
  BEGIN_EPOCH: 0
  END_EPOCH: 30
  RESUME: False
  FINETUNE_MODEL: 'knn5-q1024_model_best.pth.tar' # finetune with the best model training in CMU dataset 
  OPTIMIZER: adam
  LR: 0.0001
TEST:
  MODEL_FILE: ''  # layer 1
  BATCH_SIZE: 1
DEBUG:
  DEBUG: False
  SAVE_HEATMAPS_GT: False
  SAVE_HEATMAPS_PRED: False
  LOG_VAL_LOSS: False
MULTI_PERSON:
  SPACE_SIZE:
    - 8000
    - 8000
    - 2000
  SPACE_CENTER:
    - 2000
    - 5000
    - 1000
  MAX_PEOPLE_NUM: 10
  THRESHOLD: 0

DECODER:
  t_pose_dir: './tpose.pt'
  d_model: 256
  nhead: 8
  dim_feedforward: 1024
  dropout: 0.1
  activation: 'relu'
  num_feature_levels: 1
  num_decoder_layers: 4
  return_intermediate_dec: True
  num_keypoints: 15
  with_pose_refine: True
  aux_loss: False
  lr_linear_proj_mult: 0.1
  loss_pose_normalize: False
  loss_joint_type: 'l1'
  pred_class_fuse: 'mean'
  pred_conf_threshold: 0
  match_coord_est: 'abs'
  match_coord_gt: 'norm'
  detach_refpoints_cameraprj_firstlayer: True
  fuse_view_feats: 'cat_proj'
  epipolar_encoder: False

  optimizer: adam
  projattn_posembed_mode: ablation_not_use_rayconv
  use_feat_level:
    - 0
    - 1
    - 2
  init_ref_method: "sample_space"
  query_embed_type: "person_joint"
  query_embed_type: person_joint
  loss_pose_perprojection_2d: 5.0
  loss_pose_perjoint: 5.0
  loss_weight_loss_ce: 2.0
  feature_update_method: "MLP"
  init_self_attention: False
  open_forward_ffn: True
  query_filter_method: "all"
  init_ref_method_value: 0
  num_instance: 1024
  gt_match: True
  close_pose_embedding: False
  share_layer_weights: False
  dec_n_points: 8
  bayesian_update: False
  triangulation_method: "linalg"
  decay_method: none
  match_method: "KNN"
  match_method_value: 5
  use_ce_match: False
  filter_query: True
  loss_weight_init: 0.0
  # for panoptic to shelf/campus
  optimizer: adamw
  lr_decay_epoch: [30,]
  loss_weight_loss_ce: 0.0
  inference_conf_thr: [0.0,]
  convert_joint_format_indices: [14, 13, 12, 6, 7, 8, 11, 10, 9, 3, 4, 5, 0, 1] # used for finetuning trained mvp on one dataset to another dataset (i.e., here panoptic to shelf/campus)
